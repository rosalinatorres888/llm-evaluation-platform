site_name: LLM Evaluation Platform
site_description: Professional platform for evaluating and comparing Large Language Models
site_author: Rosalina Torres
site_url: https://github.com/rosalinatorres888/llm-evaluation-platform

theme:
  name: material
  palette:
    - scheme: default
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    - scheme: slate
      toggle:
        icon: material/brightness-4
        name: Switch to light mode
  features:
    - navigation.tabs
    - navigation.sections
    - toc.integrate
    - search.suggest
    - search.highlight
    - content.code.annotate
    - content.code.copy

nav:
  - Home: index.md
  - Getting Started:
    - Installation: getting-started/installation.md
    - Quick Start: getting-started/quickstart.md
    - Configuration: getting-started/configuration.md
  - User Guide:
    - Basic Usage: guide/basic-usage.md
    - Advanced Features: guide/advanced.md
    - Dashboard: guide/dashboard.md
  - API Reference:
    - Core Engine: api/engine.md
    - Providers: api/providers.md
    - Analytics: api/analytics.md
  - Examples:
    - Evaluation Examples: examples/evaluation.md
    - Custom Providers: examples/custom-providers.md
    - Benchmarks: examples/benchmarks.md
  - Contributing: contributing.md

plugins:
  - search
  - mkdocstrings:
      handlers:
        python:
          setup_commands:
            - import sys
            - sys.path.append("src")

markdown_extensions:
  - pymdownx.highlight
  - pymdownx.superfences
  - pymdownx.tabbed
  - admonition
  - codehilite
  - toc:
      permalink: true
