[tool.poetry]
name = "llm-evaluation-platform"
version = "2.0.0"
description = "Professional platform for evaluating and comparing Large Language Models"
authors = ["Rosalina Torres <rosalinatorres888@gmail.com>"]
license = "MIT"
readme = "README.md"
packages = [{include = "src"}]

[tool.black]
line-length = 100
target-version = ['py38', 'py39', 'py310', 'py311']
include = '\.pyi?$'

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
addopts = "-ra -q --strict-markers --cov=src --cov-report=html"

[tool.coverage.run]
source = ["src"]
omit = ["*/tests/*", "*/test_*.py"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
